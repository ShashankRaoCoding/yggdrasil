{"index":{"slug":"index","filePath":"index.md","title":"index","links":[],"tags":[],"content":" \n\t \n\t\twindow.location.href = `shashankraocoding.github.io/yggdrasil/yggdrasil` \n\t \n \n \n\t \n\t\t.page-title { \n\t\t\tfont-size: 1.70rem; \n\t\t}\n\t \n"},"yggdrasil/About-anime.js":{"slug":"yggdrasil/About-anime.js","filePath":"yggdrasil/About anime.js.md","title":"About anime.js","links":[],"tags":[],"content":"Reload this page if the animations don’t work.\n&lt;div id=&quot;circle-container&quot; style=&quot;position: relative; width: 100%; height: 400px;&quot;&gt;\n  &lt;div id=&quot;circle&quot; style=&quot;width: 50px; height: 50px; background-color: #FF6347; border-radius: 50%; position: absolute; top: 100px; left: 100px;&quot;&gt;&lt;/div&gt;\n  &lt;script src=&quot;cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js&quot;&gt;&lt;/script&gt;\n  &lt;script&gt;\n    // Animate the circle\n    document.addEventListener(&#039;DOMContentLoaded&#039;, () =&gt; {\n      anime({\n        targets: &#039;#circle&#039;,\n        translateY: [\n          { value: 300, duration: 800 },\n          { value: 0, duration: 800 },\n          { value: -300, duration: 800 },\n          { value: 0, duration: 800 },\n        ],\n        translateX: [\n          { value: 0, duration: 800 },\n          { value: 300, duration: 800 },\n          { value: 0, duration: 800 },\n          { value: -300, duration: 800 },\n        ],\n\t\tborderRadius: [\n          { value: &#039;50%&#039;, duration: 400 },\n          { value: &#039;0%&#039;, duration: 400 }\n        ],\n        direction: &#039;alternate&#039;,\n        loop: true,\n        easing: &#039;easeInOutQuad&#039;\n      });\n    });\n  &lt;/script&gt;\n&lt;/div&gt;\n\n  \n  \n  \n    // Animate the circle\n    document.addEventListener(&#039;DOMContentLoaded&#039;, () =&gt; {\n      anime({\n        targets: &#039;#circle&#039;,\n        translateY: [\n          { value: 300, duration: 800 },\n          { value: 0, duration: 800 },\n          { value: -300, duration: 800 },\n          { value: 0, duration: 800 },\n        ],\n        translateX: [\n          { value: 0, duration: 800 },\n          { value: 300, duration: 800 },\n          { value: 0, duration: 800 },\n          { value: -300, duration: 800 },\n        ],\n\t\tborderRadius: [\n          { value: &#039;50%&#039;, duration: 400 },\n          { value: &#039;0%&#039;, duration: 400 }\n        ],\n        direction: &#039;alternate&#039;,\n        loop: true,\n        easing: &#039;easeInOutQuad&#039;\n      });\n    });\n  \n"},"yggdrasil/Building-with-Go":{"slug":"yggdrasil/Building-with-Go","filePath":"yggdrasil/Building with Go.md","title":"Building with Go","links":[],"tags":[],"content":"This refers to compiling .go programs to .exe or other binary\nOn Windows:\ngo build main.go \nCompiles it and its dependencies\nIf you would like to compile your entire project package\ngo build \nDoes that!\nIf you would like to cross compile\n \nset GOOS=linux \nset GOOS=amd64 \ngo build \nIf you are on PowerShell:\n$env:GOOS=&quot;linux&quot; \n$env:GOARCH=&quot;amd64&quot; \ngo build \nIf you would like to specify the output filename\ngo build -o outputfilename "},"yggdrasil/Chemoproteogenomics":{"slug":"yggdrasil/Chemoproteogenomics","filePath":"yggdrasil/Chemoproteogenomics.md","title":"Chemoproteogenomics","links":["genomics"],"tags":[],"content":"Chemoproteogenomics is an interdisciplinary field that combines chemoproteomics and genomics to gain a deeper and more comprehensive understanding of biological systems, particularly in the context of disease like cancer.1\nHere’s a breakdown of what that means:\n\n\ngenomics: This involves studying the entire set of an organism’s genes (its genome), including genetic variations like mutations.2 In the context of chemoproteogenomics, this often involves analyzing whole exome sequencing (WES) and RNA sequencing (RNA-seq) data to identify genetic alterations.3\n\n\nChemoproteomics: This is a powerful chemical biology technique that uses small molecule probes to identify and characterize protein-small molecule interactions on a global, proteome-wide scale. It’s particularly useful for:\n\n\nIdentifying functional amino acids: For instance, it can pinpoint specific cysteine residues that are highly reactive or susceptible to modification, which often indicates their importance for protein function.4\n\n\nAssessing druggability: It can help determine which proteins or specific sites on proteins are “druggable” – meaning they can be targeted by small molecule therapies.5\n\n\nUnderstanding drug mechanisms: By identifying what proteins a drug interacts with, it can shed light on how the drug works and any potential off-target effects.6\n\n\n\n\nHow Chemoproteogenomics Integrates Them:\nThe “genomics” part informs the “chemoproteomics” part. For example, in cancer, genetic mutations can lead to altered proteins, including those with new or modified cysteine residues.7 These “gain-of-cysteine” mutations are particularly interesting because cysteine residues are often targets for chemical probes and drugs.8\nChemoproteogenomics platforms aim to:\n\n\nIdentify genetic variants: By analyzing genomic data, researchers can pinpoint mutations that lead to changes in protein sequences, such as the acquisition of new cysteines.9\n\n\nMap the functional landscape of these variants: Using chemoproteomics, they can then assess the reactivity, druggability, and functional significance of these altered or newly acquired protein sites.10 This helps understand how genetic variations translate into changes at the protein level and how these changes might impact disease or drug response.11\n\n\nGuide therapeutic discovery: By linking genetic information to protein function and druggability, chemoproteogenomics can accelerate the development of precision therapies that specifically target the unique molecular characteristics of a disease.12\n\n\nIn essence, chemoproteogenomics helps bridge the gap between genetic understanding of disease and the functional consequences at the protein level, ultimately guiding the discovery of new therapeutic strategies.13"},"yggdrasil/Download-PLINK-2":{"slug":"yggdrasil/Download-PLINK-2","filePath":"yggdrasil/Download PLINK 2.md","title":"Download PLINK 2","links":[],"tags":[],"content":"Download Plink2\nmkdir -p ~/bin &amp;&amp; source ~/.profile\nwget -P ~/bin/ s3.amazonaws.com/plink2-assets/plink2_linux_x86_64_latest.zip\nunzip ~/bin/plink2_linux_x86_64_latest.zip -d ~/bin/\nrm -v ~/bin/plink2_linux_x86_64_latest.zip\nplink2 --version\n"},"yggdrasil/Go-Concurrency-Best-Practices":{"slug":"yggdrasil/Go-Concurrency-Best-Practices","filePath":"yggdrasil/Go Concurrency Best Practices.md","title":"Go Concurrency Best Practices","links":["tags/go","tags/goroutine","tags/walk","tags/os","tags/concurrency","tags/best_practice","tags/riddle"],"tags":["go","goroutine","walk","os","concurrency","best_practice","riddle"],"content":"Can you explain what’s wrong with this code?\npackage main\n \nimport (\n    &quot;fmt&quot;\n    &quot;os&quot;\n    &quot;path/filepath&quot;\n    &quot;strings&quot;\n    &quot;sync&quot;\n)\n \nfunc main(){\n    var wg sync.WaitGroup\n    root := &quot;path/to/your/directory&quot;\n    err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {\n        if err != nil {\n            return err\n        }\n        if !info.IsDir() {\n            wg.Add(1)\n            go func() {\n                defer wg.Done()\n                newName := strings.ReplaceAll(info.Name(), &quot;old&quot;, &quot;new&quot;)\n                err := os.Rename(path, filepath.Join(filepath.Dir(path), newName))\n                if err != nil {\n                    fmt.Println(&quot;Error renaming file:&quot;, err)\n                }\n            }()\n        }\n        return nil\n    })\n    if err != nil {\n        fmt.Println(&quot;Error walking the directory:&quot;, err)\n    }\n    wg.Wait()\n}\nThe problem is that the file name is got from info.Name which returns the name of the file currently being read by the Walk function. However, because this is inside the goroutine, this means that the Walk function might be on a different file by the time info.Name is called. To circumvent this, we should call info.Name outside the goroutine and then pass the file name as a function parameter like so:\npackage main\n \nimport (\n\t&quot;fmt&quot;\n\t&quot;os&quot;\n\t&quot;path/filepath&quot;\n\t&quot;strings&quot;\n\t&quot;sync&quot;\n)\n \nfunc main() {\n\tvar wg sync.WaitGroup\n\troot := &quot;path/to/your/directory&quot; // Change to desired path or make dynamic\n\terr := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !info.IsDir() {\n\t\t\torigPath := path\n\t\t\torigName := info.Name()\n\t\t\twg.Add(1)\n\t\t\tgo func(path, name string) {\n\t\t\t\tdefer wg.Done()\n\t\t\t\tnewName := strings.ReplaceAll(name, &quot;old&quot;, &quot;new&quot;)\n\t\t\t\tnewPath := filepath.Join(filepath.Dir(path), newName)\n\t\t\t\terr := os.Rename(path, newPath)\n\t\t\t\tif err != nil {\n\t\t\t\t\tfmt.Printf(&quot;Error renaming %s to %s: %v\\n&quot;, path, newPath, err)\n\t\t\t\t}\n\t\t\t}(origPath, origName)\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tfmt.Println(&quot;Error walking the directory:&quot;, err)\n\t}\n\twg.Wait()\n}\ngo goroutine walk os concurrency best_practice riddle"},"yggdrasil/Goroutines":{"slug":"yggdrasil/Goroutines","filePath":"yggdrasil/Goroutines.md","title":"Goroutines","links":[],"tags":[],"content":"Goroutines allow concurrency in Go. Essentially, it tells Go that a function must be run asynchronously.\npackage main \n \nimport &quot;fmt&quot; \nimport &quot;time&quot; \n \nfunc main(){ \n\tgo func(){ // call the goroutine with an anonymous function \n\t\ttime.Sleep(time.Second) \n\t\tfmt.Println(&quot;Goroutines are useful??&quot;) \n\t}() // This pair of brackets are important as it means that you are calling the function immediately \n\ttime.Sleep(time.Second * 2) // wait for the go routine to complete \n}\nThis is fine for now, but often you may have to wait an unknown amount of time. For this, we use channels and blocking.\npackage main \n \nimport &quot;fmt&quot; \nimport &quot;time&quot; \nimport &quot;math/random&quot; \n \nfunc main(){ \n\tstat := make(chan string) \n\tgo func(stat chan string){ \n\t\ttime.Sleep(time.Second * random.Intn(100)) // wait for a random amount of time \n\t\tstat &lt;- &quot;Hi!!&quot; \n\t}(stat)\n\tmsg := &lt;- stat // the programme waits here till a message is received \n\tfmt.Println(msg) \n}\nChannels in Go are often refferred to as pipes. These are, as their names may suggest, storage containers that allow their contents to be transported. In Go, this means transportation between Goroutines.\nIn out code, the go func(){...}(stat) function call is asynchronous, does its processing, and outputs the result into stat\nOn the outside, the programme continue till it reaches &lt;- stat which causes the programme to wait till a message arrives.\n\n\n                  \n                  Note\n                  \n                \n\n\nIf there is no receiver, the sender won’t send\nThis means that the sender also blocks till the receiver is ready\nIf there is no sender, the receiver won’t receive\nAt a time, only one item may be in the channel\nThe channel is strictly typed\n\n\n\nThe third point in the above note does have an exception, though: buffered channels. These are channels where you have predefined a holding capacity. For example:\nchannel := make(chan string, 2) \nHolds 2 strings.\nHowever, this means that it is no longer blocking - unless the capacity is exceeded.\n\n\n                  \n                  Key\n                  \n                \n\n\nA channel pull or push becomes blocking if the channel is full. An unbuffered channel has a capacity of 0 and is thus blocking. Other channels must first exceed capacity.\n\n\n\nBut what if you’d like to wait for multiple Go routines to finish?\nYou could type\n&lt;- chan1 \n&lt;- chan2 \n&lt;- chan3 \nBut that’s tedious. You can use a WaitGroup!\npackage main \n \nimport ( \n\t&quot;time&quot;\n\t&quot;sync&quot; \n\t&quot;fmt&quot; \n)\n \nmain func(){ \n\tvar wg sync.WaitGroup \n\twg.Add(1) \n\tgo func(){ \n\t\tdefer wg.Done() \n\t\ttime.Sleep(time.Second * 2) \n\t}() \n\twg.Wait() \n\tfmt.Println(&quot;Yey!!&quot;) \n}\nThe above code initialises a waitgroup tracker, then adds 1 to tell the waitgroup tracker how many goroutines were initialised. From there, a wg.Done method is called once each go routine is done, telling the waitgroup tracker that it has to wait on 1 fewer goroutines. wg.Wait is blocking. Using wg.Add(1) within the goroutine could make it so that we.Wait() is called before wg.Add. Also, passing wg into a function requires &amp;wg as this is not a reference type."},"yggdrasil/MAVE-Assays":{"slug":"yggdrasil/MAVE-Assays","filePath":"yggdrasil/MAVE Assays.md","title":"MAVE Assays","links":[],"tags":[],"content":"MAVE assays — short for Multiplexed Assays for Variant Effect — are experimental techniques used to measure the functional impact of many genetic variants at once. Instead of testing one mutation at a time, MAVE lets researchers test thousands (or more) of variants simultaneously in a high-throughput way.\n🔬 What does a MAVE assay do?\nIt assesses how each possible mutation (or variant) in a target gene or protein affects its function, expression, or interaction. This helps in:\n\n\nUnderstanding which mutations are damaging or benign\n\n\nPredicting disease risk\n\n\nCreating better functional annotations for genes\n\n\n\n🧪 How does it work (simplified)?\n\n\nMutant Library: You create a large library of gene variants (e.g., all possible single-nucleotide changes).\n\n\nIntroduce into Cells: You introduce these into cells or organisms in a pooled format.\n\n\nFunctional Selection or Screening: You apply a selection pressure or perform a functional assay that lets you distinguish variants (e.g., by growth, binding ability, fluorescence).\n\n\nSequencing: You use next-generation sequencing to see which variants enriched or depleted under the condition.\n\n\nScoring: You calculate a functional score for each variant — showing how “good” or “bad” it is compared to the wild-type.\n\n\n\n🧠 Why are MAVE assays powerful?\nThey allow:\n\n\nSystematic mapping of genotype–phenotype relationships\n\n\nStudy of variants of unknown significance (VUS) in clinical genetics\n\n\nTesting drug effects on mutant proteins\n\n\nBenchmarking and improving computational variant effect predictors\n\n\n\n🔁 Example Techniques\nSome common forms of MAVE assays:\n\n\nDeep Mutational Scanning (DMS): Often used on proteins\n\n\nSaturation Genome Editing (SGE): Used to test all variants at a locus using CRISPR\n\n\nMassively Parallel Reporter Assays (MPRA): Used to test variants in regulatory DNA\n\n\n"},"yggdrasil/PLINK-(Complete)":{"slug":"yggdrasil/PLINK-(Complete)","filePath":"yggdrasil/PLINK (Complete).md","title":"PLINK (Complete)","links":["yggdrasil/Download-PLINK-2","tags/coding","tags/bash","tags/biology"],"tags":["coding","bash","biology"],"content":"For some useful PLINK Code, see Download PLINK 2\nPLINK is a popular open-source genetic data analysis tool primarily used in genome-wide association studies (GWAS) and population genetics. It’s super efficient for handling large-scale genotype data, especially in .ped/.map or .bed/.bim/.fam formats.\n🔹 What it does:\n\nData filtering (e.g., MAF, HWE, missingness)\nAssociation testing (case/control, quantitative traits)\nLD pruning and clumping\nIBD/IBS analysis\nPCA for population structure\nFile format conversion (e.g., VCF → PLINK)\n\n🔹 Common PLINK commands:\nplink --bfile data --assoc         # Basic association test\nplink --bfile data --make-bed      # Convert to binary PLINK format\nplink --bfile data --pca           # Principal component analysis\n🔹 Why people love it:\n\nIt’s lightweight and fast\nEasy to script in pipelines\nPlays well with R, Python, and other tools like REGENIE, BOLT-LMM, and PRSice\n\nIf you’re starting with GWAS or QC, PLINK is pretty much your go-to tool.\ncoding bash biology"},"yggdrasil/Pandas-(Complete)":{"slug":"yggdrasil/Pandas-(Complete)","filePath":"yggdrasil/Pandas (Complete).md","title":"Pandas (Complete)","links":["yggdrasil/Pandas-Cheat-Sheet-(General-Use)"],"tags":[],"content":"For quick syntax help, see Pandas Cheat Sheet (General Use)"},"yggdrasil/Pandas-Cheat-Sheet-(General-Use)":{"slug":"yggdrasil/Pandas-Cheat-Sheet-(General-Use)","filePath":"yggdrasil/Pandas Cheat Sheet (General Use).md","title":"Pandas Cheat Sheet (General Use)","links":[],"tags":[],"content":"1. Importing and Creating DataFrames\nimport pandas as pd\n \n# From CSV / Excel\ndf = pd.read_csv(&#039;file.csv&#039;)\ndf = pd.read_excel(&#039;file.xlsx&#039;)\n \n# From dictionary\ndf = pd.DataFrame({&#039;name&#039;: [&#039;Alice&#039;, &#039;Bob&#039;], &#039;age&#039;: [25, 30]})\n\n2. Inspecting Data\ndf.head()         # First 5 rows\ndf.tail()         # Last 5 rows\ndf.info()         # Summary of columns, non-nulls\ndf.describe()     # Stats for numeric cols\ndf.shape          # (rows, columns)\ndf.columns        # Column names\ndf.dtypes         # Data types\n\n3. Selecting Data\ndf[&#039;col&#039;]                     # One column\ndf[[&#039;col1&#039;, &#039;col2&#039;]]          # Multiple columns\ndf.iloc[0]                    # First row (by position)\ndf.loc[0]                     # First row (by index)\ndf.loc[0, &#039;col&#039;]              # Cell by label\ndf.iloc[0, 1]                 # Cell by position\n \ndf[df[&#039;age&#039;] &gt; 25]            # Conditional selection\n\n4. Modifying Data\ndf[&#039;new&#039;] = df[&#039;age&#039;] + 1     # New column\ndf.rename(columns={&#039;old&#039;: &#039;new&#039;})    # Rename column\ndf.drop(&#039;col&#039;, axis=1)        # Drop column\ndf.drop(0, axis=0)            # Drop row by index\n \n# Note: use | and &amp; \n\n5. Mapping &amp; Applying\ndf[&#039;col&#039;].map(lambda x: x*2)             # Element-wise map (you can also use a dictionary) \ndf[&#039;col&#039;].apply(custom_func)            # Custom function\ndf.apply(func, axis=1)                  # Row-wise\ndf.applymap(str.upper)                  # Whole DataFrame\n\n6. Cleaning Data\ndf.dropna()                  # Drop rows with NaN\ndf.fillna(0)                 # Fill NaNs\ndf[&#039;col&#039;].str.strip()        # Remove whitespace\ndf[&#039;col&#039;].astype(int)        # Convert type\ndf.duplicated().sum()        # Count duplicates\ndf.drop_duplicates()         # Remove duplicates\n\n7. Grouping &amp; Aggregating\ndf.groupby(&#039;col&#039;).mean()\ndf.groupby(&#039;col&#039;)[&#039;val&#039;].sum()\ndf.pivot_table(index=&#039;A&#039;, columns=&#039;B&#039;, values=&#039;C&#039;, aggfunc=&#039;sum&#039;)\n\n8. Merging &amp; Joining\npd.concat([df1, df2])                       # Stack vertically\npd.merge(df1, df2, on=&#039;key&#039;)               # SQL-style join\npd.merge(df1, df2, how=&#039;left&#039;, on=&#039;key&#039;)   # Left join\n\n9. Exporting\ndf.to_csv(&#039;output.csv&#039;, index=False)\ndf.to_excel(&#039;output.xlsx&#039;)\n\n10. Useful Tricks\ndf[&#039;col&#039;].value_counts()      # Count unique values\ndf.sort_values(by=&#039;col&#039;)      # Sort by column\ndf.sample(n=5)                # Random sample\ndf.reset_index(drop=True)     # Reset index\n11. Group Data\ngrouped = data.groupby(&quot;GroupColumn&quot;)\n“Split data per unique value in GroupColumn.”\n✅ Example:\nSay your data looks like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroupColumnNumericalColumnA3A5B2B4A7\nWould output:\nA\n  GroupColumn  NumericalColumn\n0           A                3\n1           A                5\n4           A                7\n\nB\n  GroupColumn  NumericalColumn\n2           B                2\n3           B                4\n\nThe above output is produced by the code:\nfor group, group_data in data.groupby(&quot;GroupColumn&quot;):\n    print(group)\n    print(group_data)"},"yggdrasil/Piping-File-Contents-to-Ollama3":{"slug":"yggdrasil/Piping-File-Contents-to-Ollama3","filePath":"yggdrasil/Piping File Contents to Ollama3.md","title":"Piping File Contents to Ollama3","links":[],"tags":[],"content":"Use this code to pipe a file’s contents directly to llama3:\nGet-Content &quot;filepath&quot; | ollama run llama3 &quot;prompt&quot; \n "},"yggdrasil/Python-DataSci-Libs":{"slug":"yggdrasil/Python-DataSci-Libs","filePath":"yggdrasil/Python DataSci Libs.md","title":"Python DataSci Libs","links":["yggdrasil/Pandas-(Complete)","yggdrasil/Sea-Born's-Data-Visualisation-Code","Matplotlib"],"tags":[],"content":"You should be familiar with:\n\n Pandas (Complete) (tables)\n Sea Born’s Data Visualisation Code (visualisation)\n Matplotlib (visualisation)\n"},"yggdrasil/Python-to-work-with-GZIP":{"slug":"yggdrasil/Python-to-work-with-GZIP","filePath":"yggdrasil/Python to work with GZIP.md","title":"Python to work with GZIP","links":[],"tags":[],"content":"Useful python to read and write to and from a gzip\nimport gzip\n \n# Writing as text\nwith gzip.open(&#039;output.txt.gz&#039;, &#039;wt&#039;) as f:  # &#039;wt&#039; = write text\n    f.write(&quot;Hello, GZIP!\\nThis is a test.&quot;)\n \n# Writing as binary\nwith gzip.open(&#039;output.txt.gz&#039;, &#039;wb&#039;) as f:\n    f.write(b&quot;Binary data here\\nAnother line&quot;)\n \nimport gzip\n \n# Reading as text (e.g., CSV, JSON, etc.)\nwith gzip.open(&#039;file.txt.gz&#039;, &#039;rt&#039;) as f:  # &#039;rt&#039; = read text\n    for line in f:\n        print(line.strip())\n \n# Reading as binary\nwith gzip.open(&#039;file.txt.gz&#039;, &#039;rb&#039;) as f:\n "},"yggdrasil/REGENIE-(Complete)":{"slug":"yggdrasil/REGENIE-(Complete)","filePath":"yggdrasil/REGENIE (Complete).md","title":"REGENIE (Complete)","links":["yggdrasil/polygenic-risk-score"],"tags":[],"content":"What it is\nEssentially, it is a tool that allows you to test GWAS signals/genetic instrument associations while accounting for ancestry.\nSome users have reported issues like inflated p‑values under certain settings—though these often require careful QC and parameter tuning to resolve opensourcebiology.eu.sa\nHow it works\nImagine some dummy data for an organism that has 4 genes\nIndividual A has a trait and mutant genetic variants of genes 2, 3, and 4.\nIndividual B has the same trait and the same genetic variants on genes 3 and 4.\nThere are other individuals also, such that they model the data below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenotypeTrait123412340.81340.9120.110.2This could lead us to believe that the genetic variants on genes 3 and 4 are responsible for the trait, but in reality the trait on gene 4 is a covariate because A and B are related.\nIf we just did a simple association test for gene 4 now, we would be lead to think that gene 4 is causally related to the trait. The issue is that we don’t have a data point for genotype 1, 2, 3. We also don’t have a datapoint with just genotype 4.\nNote, even if we did have these, that would not solve the true problem, as in reality we likely have 100s of genes that each contribute a little, and thus we have small values for all of them. However, for the purposes of this example, let’s continue with 4 genes.\nBut we can use the statistics from rest of the population to essentially predict how a person with genotype 1, 2, 3 would show the trait. This is the polygenic risk score prediction.\nTo do this, we first calculate the risk of 1, 2, 3 using statistics magic. Suppose this yields an association score of 0.8.\nNow genotype gene 4’s association with the trait is calculated from all of the other genotypes, which include 1, 2, 3 and comes up with an association score of 0.8. But this test included the genotypes 1, 2, 3, and many others with those genes. We adjust for them with the earlier 0.8, since we have their association with the trait. This shows us that 4 actually does not correlate with the trait.\nWhen we do the same thing the other way around, genotype 1, 2, 4 would give 0.2, and genotype 1, 2, 3, 4 would give 0.80, and adjusted for the effects of genotype 1, 2, 4, 3 would give still give 0.6. This shows that 3 is actually related.\nThere is a problem when both contribute significantly, e.g. 3, and 4, 0.8, and 0.8. This is not handled by Regenie.\nStatistics Magic\nThis is the calculation of the polygenic risk score."},"yggdrasil/Sea-Born's-Data-Visualisation-Code":{"slug":"yggdrasil/Sea-Born's-Data-Visualisation-Code","filePath":"yggdrasil/Sea Born's Data Visualisation Code.md","title":"Sea Born's Data Visualisation Code","links":[],"tags":[],"content":"To import sea born, use\nimport seaborn \n \nTo plot a histogram, use\nseaborn.histplot(data = data, x=&quot;Name of Column with numerical value&quot;, hue=&quot;Name of y axis variable&quot;, binwidth = 2, multiple=&quot;stack&quot;) \nseaborn.histplot() takes data as a pandas table, and subsequent arguments are the column names. x is a column name, and the hue is also a column name. binwidth is self explaining and multiple=&quot;stack&quot; is an optional argument showing that the data parts need to be stacked.\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n \n# Plot the histogram\nsns.histplot(data=data, x=&quot;Name of Column with numerical value&quot;, hue=&quot;Name of y axis variable&quot;, binwidth=2, multiple=&quot;stack&quot;)\n \n# Mean line\nmean_value = data[&quot;Name of Column with numerical value&quot;].mean()\nplt.axvline(mean_value, color=&#039;red&#039;, linestyle=&#039;dashed&#039;, linewidth=2, label=f&#039;Mean: {mean_value:.2f}&#039;)\n \n# Move legend outside to the right\nplt.legend(loc=&#039;upper left&#039;, bbox_to_anchor=(1, 1))\n \n# Adjust layout so the legend isn&#039;t cut off\nplt.tight_layout()\n \n# Show plot\nplt.show()\n "},"yggdrasil/VCF-(Complete)":{"slug":"yggdrasil/VCF-(Complete)","filePath":"yggdrasil/VCF (Complete).md","title":"VCF (Complete)","links":["yggdrasil/PLINK-(Complete)"],"tags":[],"content":"🧬 What is a VCF File?\nVCF stands for Variant Call Format. It’s a standard text file format used in bioinformatics to store genetic variant data—like SNPs (single nucleotide polymorphisms), insertions, deletions, and structural variants—detected from sequencing data.\n\n📦 VCF File Structure\nA typical VCF file has two main sections:\n\n\nHeader (starts with ## or #)\n\n\nData Records (tab-delimited columns)\n\n\n\n1. 📝 Header\n\n\nStarts with multiple ## metadata lines (e.g. info about reference genome, filters, formats).\n\n\nThe final header line begins with #CHROM and defines the column names.\n\n\nExample:\n##fileformat=VCFv4.2\n##INFO=&lt;ID=DP,Number=1,Type=Integer,Description=&quot;Total Depth&quot;&gt;\n##FORMAT=&lt;ID=GT,Number=1,Type=String,Description=&quot;Genotype&quot;&gt;\n#CHROM POS ID REF ALT QUAL FILTER INFO FORMAT Sample1 Sample2\n\n2. 🔢 Data Rows\nEach line is a variant record with at least these columns:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumnMeaningCHROMChromosomePOSPosition on the chromosomeIDVariant ID (e.g., dbSNP rsID)REFReference alleleALTAlternate allele(s)QUALQuality score of the variantFILTERFilter status (e.g., PASS)INFOKey-value pairs with extra detailsFORMATHow to interpret sample columnsSample(s)Genotype data per individual\nExample:\nchr1  1234567  rs123456  G  A  50  PASS  DP=100  GT  0/1  1/1\n\n🔍 INFO and FORMAT Fields\nThese are semicolon- or colon-delimited fields holding detailed info:\n\n\nINFO=DP=100: Depth of reads\n\n\nFORMAT=GT:AD: Genotype, Allelic Depth\n\n\nSample1=0/1:35,65: Heterozygous with 35 REF reads and 65 ALT reads\n\n\n\n📁 File Extensions\n\n\n.vcf: plain text\n\n\n.vcf.gz: compressed version (bgzip + tabix index)\n\n\n\n🛠 Tools That Use VCFs\n\n\nbcftools, vcftools – for manipulating VCFs\n\n\nPLINK (Complete), GATK, SAMtools – common in pipelines\n\n\nANNOVAR, VEP – for annotating variants\n\n\n"},"yggdrasil/What-is-Mendelian-Randomisation":{"slug":"yggdrasil/What-is-Mendelian-Randomisation","filePath":"yggdrasil/What is Mendelian Randomisation.md","title":"What is Mendelian Randomisation","links":[],"tags":[],"content":"\n\n                  \n                  Video\n                  \n                \n\n\nThis video does a really good job explaining it.\nyoutu.be/LoTgfGotaQ4\n\n\n\n\n"},"yggdrasil/bed-file-format":{"slug":"yggdrasil/bed-file-format","filePath":"yggdrasil/bed file format.md","title":"bed file format","links":["yggdrasil/Download-PLINK-2"],"tags":[],"content":"The .bed format is a binary file format that can be generated using Plink2. It can also be generated from plink1.9, though this is not something that you have tried before.\nDownload PLINK 2 should help you with generating a .bed from .bgen using PLINK2."},"yggdrasil/polygenic-risk-score":{"slug":"yggdrasil/polygenic-risk-score","filePath":"yggdrasil/polygenic risk score.md","title":"polygenic risk score","links":[],"tags":[],"content":"TLDR?\nA polygenic risk score (PRS) is a way to estimate an individual’s genetic predisposition to a certain trait or disease by combining the effects of many genetic variants across the genome.\n\n🔬 What Is It?\nA PRS summarizes the cumulative effect of many single-nucleotide polymorphisms (SNPs), each of which contributes a small amount to the risk of a complex trait (like heart disease, diabetes, height, or intelligence).\n\n🧮 How Is It Calculated?\nAt a high level, the formula looks like this:\nPRS=∑i=1nβi⋅Gi\\text{PRS} = \\sum_{i=1}^{n} \\beta_i \\cdot G_i\nWhere:\n\n\nβi\\beta_i: Effect size (log-odds or regression coefficient) of SNP ii, typically from a GWAS summary statistics file\n\n\nGiG_i: The individual’s genotype at SNP ii, usually encoded as 0, 1, or 2 copies of the risk allele\n\n\nnn: Number of SNPs included in the score (often filtered by p-value, LD pruning, etc.)\n\n\n\n🛠️ Steps to Calculate PRS\n\n\nGet GWAS Summary Statistics\nFrom a large, high-quality genome-wide association study (GWAS), download effect sizes (usually beta or odds ratio), p-values, and SNP IDs.\n\n\nQuality Control &amp; Filtering\n\n\nRemove ambiguous SNPs (e.g., A/T or C/G)\n\n\nApply p-value threshold (e.g., p&lt;1e−5p &lt; 1e-5) or use all SNPs\n\n\nPerform LD pruning to reduce correlation between nearby SNPs\n\n\n\n\nMatch SNPs to Genotype Data\n\nMake sure the SNPs in the GWAS summary stats match those in your individual-level genotype dataset (e.g., PLINK .bed/.bim/.fam files)\n\n\n\nCalculate the Weighted Sum\n\n\nFor each SNP: multiply the number of risk alleles (0, 1, 2) by the GWAS effect size\n\n\nSum over all selected SNPs to get the individual’s raw PRS\n\n\n\n\nStandardize the Score (optional)\n\n\nYou can z-score normalize across individuals in the cohort:\nzPRSi=PRSi−μσ\\text{zPRS}_i = \\frac{\\text{PRS}_i - \\mu}{\\sigma}\nwhere μ\\mu and σ\\sigma are the mean and standard deviation across individuals\n\n\n\n\n\n🧠 Example\nSay we use 3 SNPs:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSNPEffect Size (β)Genotype (G)rs10.122rs2-0.081rs30.200\nThen:\nPRS=(0.12×2)+(−0.08×1)+(0.20×0)=0.24−0.08+0=0.16\\text{PRS} = (0.12 \\times 2) + (-0.08 \\times 1) + (0.20 \\times 0) = 0.24 - 0.08 + 0 = 0.16\n\n🧰 Common Tools\n\n\nPLINK: Widely used for genotype handling and PRS calculation\n\n\nPRSice: Automates PRS calculation and clumping\n\n\nLDpred: Bayesian method that adjusts effect sizes for LD\n\n\nscikit-learn or R for custom pipelines and machine learning on PRS\n\n\n\n⚠️ Notes &amp; Limitations\n\n\nPRS performance depends heavily on the ancestry match between your target individual and the GWAS cohort.\n\n\nEnvironmental and lifestyle factors aren’t captured.\n\n\nSome diseases are oligogenic or monogenic, not suitable for PRS.\n\n\n"}}